{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucion Challenge Latam\n",
    "## Nelson David Navarro Diaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota. La explicacion detalla de cada una de las operaciones hara parte de los comentarios de cada funcion, los comentarios se haran en ingles entendiendo las buenas practicas de comentar en este idioma, debido a que este idioma no nos limitaria a compartirlo con personas no hispanohablantes. Este documento si se hace en espanol por ser el idioma de los involucrados en este proceso de seleccion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de inicial el desarrollo de cada uno de los casos aplicando es necesario hacer una revision de los datos que tenemos. Esto debido a que el entender el negocio y las condiciones de los datos que se estaran procesando es el primera paso para desarrollar una solucion.  Ya que el entender el origen, la naturaleza de los datos y la aplicacion que le vamos a dar a estos es lo que finalmente nos permitira tomar las decisiones adecuadas en el desarrollo de una solucion.  En este caso particular tenemos los siguientes insigths. \n",
    "-  La informacion tiene como origen la plataforma X antes twitter y al ser la informacion publicada por estos no solo tiene la informacion necesaria en cada caso, sino que tambien esta cargada de informacion adicional.\n",
    "- Aunque en este momento tenemos un set de datos limitados este podria seguir creciendo indefinidamente ya que esta informacion se genera en tiempo real en esta aplicacion. \n",
    "- La informacion ingresa en un formato Json con Child Json, por lo que alguna informacion no  podra ser leida en el primer nivel de exploracion del Json. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Las top 10 fechas donde hay m√°s tweets. Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as. Debe incluir las siguientes funciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Optimizacion del tiempo de ejecucion.\n",
    "Incialmente considerando que la informacion viene  en formato Json el primer paso es transformarlo a un tipo de datos mucho mas facil de manejar. En este caso se procede a pasaralo a dataframe de pyspark. Debido a que este formato es columnar lo que al trabajar con grandes datos nos permite utilizar unicamente las colummnas que requerimos lo que hace que se trabaje con menos informacion. En este caso como se busca la optimizacion del tiempo se haran los procesos utilizando la totalidad del archivo  lo que hara que cada una de las operaciones se haga de una vez sobre la totalidad del archivo.\n",
    "\n",
    "AHora procedemos a llamar la funcion, inicialmente medimos tiempo de ejecucion, memoria y vemos el resultado la ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 58s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "%timeit -r 1 -n 1 result_list = q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 511.2421875 MiB\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "from q1_time import q1_time\n",
    "mem_usage = memory_usage((q1_time, (file_path,)), interval=1, timeout=None)\n",
    "print(f\"Memory usage: {max(mem_usage)} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2021-02-18', 'neetuanjle_nitu'), ('2021-02-13', 'MaanDee08215437'), ('2021-02-17', 'RaaJVinderkaur'), ('2021-02-16', 'jot__b'), ('2021-02-20', 'MangalJ23056160'), ('2021-02-14', 'rebelpacifist'), ('2021-02-15', 'jot__b'), ('2021-02-23', 'Surrypuria'), ('2021-02-19', 'Preetm91'), ('2021-02-12', 'RanbirS00614606')]\n"
     ]
    }
   ],
   "source": [
    "result_list = q1_time(file_path)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optimizacion del uso Memoria:  Para este caso de aplicacion particular buscando optimizar la memoria se procesara por chunks o fragmentos del archivo inicial esto con la finalidad de tener dataframes que ocupen menos espacio ya que en cada lectura solamente se tendria acumulado un fragmento del archivo en memoria, se evaluaria y se almacena unicamente el resultado de esa transaccion  al final se hace una exploracion conjunta de los resultados. De tal manera que se tendrian los resultados consolidado. Esto requiere mayor tiempo de procesamiento pero el uso de memoria se mantendra bajo. Bajo este mismo concepto se maneja tambien en aplicaciones real time, lo cual podria ser conveniente teniendo en cuenta la plataforma de origen de estos datos, ya que una implementacion como esta nos permitira  leer en tiempo real la informacion que se va generando y al final ir viendo como va cambiando los insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 99.55078125 MiB\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "from q1_memory import q1_memory\n",
    "mem_usage = memory_usage((q1_memory, (file_path,)), interval=1, timeout=None)\n",
    "print(f\"Memory usage: {max(mem_usage)} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 49s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "%timeit -r 1 -n 1 result_list = q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2021-02-18', 'neetuanjle_nitu'), ('2021-02-13', 'Preetm91'), ('2021-02-22', 'preetysaini321'), ('2021-02-17', 'RaaJVinderkaur'), ('2021-02-16', 'jot__b'), ('2021-02-21', 'Surrypuria'), ('2021-02-20', 'MangalJ23056160'), ('2021-02-14', 'rebelpacifist'), ('2021-02-15', 'jot__b'), ('2021-02-23', 'Surrypuria'), ('2021-02-19', 'Preetm91'), ('2021-02-12', 'RanbirS00614606')]\n"
     ]
    }
   ],
   "source": [
    "result_list = q1_memory(file_path)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones: Se ve que en la primera manera se hace en menor tiempo y en la segunda se reduce el consumo de memoria si quisieramos mejorar el uso de memoria hariamos el tamano del fragmento a explorar mas pequeno pero tardariamos mas tiempo. Ahi debemos jugar con los recursos disponibles para tomar una decision en este caso vemos que un tamano de 100 000 lineas no se alarga demasiado el procesamiento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los top 10 emojis m√°s usados con su respectivo conteo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. En este caso particular se encuentra la posibilidad de que solo se debe leer un valor del json para esto se lee en una lista y luego se crea un solo string para alamacenar todo, esto debido a que no nos interesa saber quien dio la informacion solo que se repita y el procesarlo como un string nos da la ventaja de trabajar con un solo gran bloque de texto sin estructura que nos reducce el procesamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.4 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from q2_time import q2_time\n",
    "%timeit -r 1 -n 1 result_list = q2_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 361.74588815789474 MiB\n",
      "[107.4765625, 107.5625, 198.99609375, 303.66796875, 406.4609375, 496.640625, 517.546875, 522.42578125, 527.87890625, 532.28515625, 537.13671875, 541.86328125, 546.79296875, 552.19921875, 233.9140625, 209.72265625, 209.7890625, 209.7890625, 111.0234375]\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "from q2_time import q2_time\n",
    "from statistics import mean\n",
    "\n",
    "mem_usage = memory_usage((q2_time, (file_path,)), interval=1, timeout=None)\n",
    "print(f\"Memory usage: {mean(mem_usage)} MiB\")\n",
    "print(mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n"
     ]
    }
   ],
   "source": [
    "result= q2_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. memory optimization. En este caso se toma el mismo abordaje que en el primero, se hace la division por strings mas pequenos teniendo asi un procesamiento mas pequeno de los datos que se estan manejando.  Siguiendo el mismo concepto de los chunks del punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.9 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "%timeit -r 1 -n 1 result_list = q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 366.621484375 MiB\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "from q2_memory import q2_memory\n",
    "from statistics import mean\n",
    "\n",
    "mem_usage = memory_usage((q2_memory, (file_path,)), interval=1, timeout=None)\n",
    "print(f\"Memory usage: {mean(mem_usage)} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "result= q2_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones. En este caso al no tener datos que sean de estructura compleja entre una alternativa y otra no se tiene una diferencia significativa como si se noto en el caso anterior. Esto debido a que se estaba trabajando solo con el texto que resulta ser mas ligero de procesar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos. Debe incluir las siguientes funciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opcion 1. Para este caso particular para abordar la reduccion de tiempo se hara una lectura directa del jSon tomando asi un acceso rapido a la columna que se necesita. Ahora en este caso particular como se tiene que cada uno de los twitts puede tener multiples menciones se hace un expand de la lista de user mencionados. Este proceso se hace con pyspark por las funcionalidades correspondientes para hacer conteos facilitando hacia sacar el rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from q3_time import q3_time\n",
    "%timeit -r 1 -n 1 result_list = q3_time(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 101.26953125 MiB\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "from q3_time import q3_time\n",
    "mem_usage = memory_usage((q3_time, (file_path,)), interval=1, timeout=None)\n",
    "print(f\"Memory usage: {max(mem_usage)} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "result= q3_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcion 2.Para la opcion de buscar la reduccion del consumo de memoria se sigue el manejo de chunks para esto se explora el archivo linea a linea teniendo asi. la conformacion del fragamento que se va a usar para el procesamiento no se tenga la totalidad del archivo almacenado sino unicamente la que esta siendo procesada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.08 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "%timeit -r 1 -n 1 result_list = q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 108.890625 MiB\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "from q3_memory import q3_memory\n",
    "mem_usage = memory_usage((q3_memory, (file_path,)), interval=1, timeout=None)\n",
    "print(f\"Memory usage: {max(mem_usage)} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "result= q3_memory(file_path)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
